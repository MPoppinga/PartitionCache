name: Integration Tests

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

env:
  CI: true
  PYTHON_VERSION: "3.12"

jobs:
  build-postgres-image:
    name: Build PostgreSQL Image with Extensions
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    outputs:
      image-tag: sha-${{ steps.sha.outputs.short }}
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Get short SHA
      id: sha
      run: echo "short=${GITHUB_SHA::7}" >> $GITHUB_OUTPUT

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Log in to GitHub Container Registry
      uses: docker/login-action@v3
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ghcr.io/mpoppinga/postgres-test-extensions
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha,prefix=sha-
          type=raw,value=latest,enable={{is_default_branch}}

    - name: Build and push PostgreSQL image
      uses: docker/build-push-action@v5
      with:
        context: .github/docker/postgres-cron
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        platforms: linux/amd64

  integration-tests:
    name: ${{ matrix.name }}
    runs-on: ubuntu-latest
    needs: build-postgres-image
    
    strategy:
      fail-fast: false
      matrix:
        include:
          - name: "PostgreSQL Backends"
            pattern: "postgresql"
            suffix: "pg"
            parallel: true
            requires_redis: false
            job_index: 0
            redis_bit_db: 10
          - name: "Redis Backends"
            pattern: "redis"
            suffix: "redis"
            parallel: true
            requires_redis: true
            job_index: 1
            redis_bit_db: 11
          - name: "RocksDB Backends"
            pattern: "rocksdb"
            suffix: "rocksdb"
            parallel: false
            requires_redis: false
            job_index: 2
            redis_bit_db: 12
          - name: "Queue Processing"
            pattern: "queue"
            suffix: "queue"
            parallel: false
            requires_redis: false
            job_index: 3
            redis_bit_db: 13
          - name: "CLI Tools"
            pattern: "test_cli"
            suffix: "cli"
            parallel: true
            requires_redis: false
            job_index: 4
            redis_bit_db: 14

    services:
      postgres:
        image: ghcr.io/mpoppinga/postgres-test-extensions:${{ needs.build-postgres-image.outputs.image-tag }}
        env:
          POSTGRES_DB: partitioncache_integration
          POSTGRES_USER: integration_user
          POSTGRES_PASSWORD: integration_password
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U integration_user -d partitioncache_integration"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10
      
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10

    env:
      # Define a unique database name for each job
      UNIQUE_DB_NAME: partitioncache_integration_${{ matrix.suffix }}_${{ github.run_id }}
      BASE_TEMPLATE_DB: partitioncache_integration
      
      # PostgreSQL configuration
      PG_HOST: localhost
      PG_PORT: 5432
      PG_USER: integration_user
      PG_PASSWORD: integration_password
      
      # Database configuration
      DB_HOST: localhost
      DB_PORT: 5432
      DB_USER: integration_user
      DB_PASSWORD: integration_password
      
      # Queue configuration
      PG_QUEUE_HOST: localhost
      PG_QUEUE_PORT: 5432
      PG_QUEUE_USER: integration_user
      PG_QUEUE_PASSWORD: integration_password
      QUERY_QUEUE_PROVIDER: postgresql
      
      # Redis configuration - isolated per job to prevent conflicts
      REDIS_HOST: localhost
      REDIS_PORT: 6379
      REDIS_CACHE_DB: ${{ matrix.job_index }}
      REDIS_BIT_DB: ${{ matrix.redis_bit_db }}
      REDIS_BIT_BITSIZE: 200000
      REDIS_SET_HOST: localhost
      REDIS_SET_PORT: 6379
      REDIS_SET_DB: ${{ matrix.job_index }}
      
      # Cache backend configuration with job-specific prefixes
      PG_ARRAY_CACHE_TABLE_PREFIX: ci_array_cache_${{ matrix.suffix }}
      PG_BIT_CACHE_TABLE_PREFIX: ci_bit_cache_${{ matrix.suffix }}
      PG_BIT_CACHE_BITSIZE: 200000
      PG_ROARINGBIT_CACHE_TABLE_PREFIX: ci_roaring_cache_${{ matrix.suffix }}
      
      # RocksDB configuration - isolated per job to prevent file conflicts
      ROCKSDB_PATH: /tmp/ci_rocksdb_${{ matrix.suffix }}_${{ github.run_id }}
      ROCKSDB_BIT_PATH: /tmp/ci_rocksdb_bit_${{ matrix.suffix }}_${{ github.run_id }}
      ROCKSDB_BIT_BITSIZE: 200000
      ROCKSDB_DICT_PATH: /tmp/ci_rocksdict_${{ matrix.suffix }}_${{ github.run_id }}

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Setup micromamba
      uses: mamba-org/setup-micromamba@v1
      with:
        micromamba-version: 'latest'
        environment-file: .github/micromamba-env.yml
        init-shell: >-
          bash
        cache-environment: true
        post-cleanup: 'all'

    - name: Install PartitionCache
      shell: micromamba-shell {0}
      run: |
        pip install -e ".[testing,db]"
        pip install pytest-xdist  # Additional for parallel execution

    - name: Create and configure test database
      shell: micromamba-shell {0}
      run: |
        echo "Waiting for PostgreSQL..."
        for i in {1..30}; do
          if python -c "import psycopg; psycopg.connect('postgresql://integration_user:integration_password@localhost:5432/partitioncache_integration')" 2>/dev/null; then
            echo "PostgreSQL ready"
            break
          fi
          sleep 2
        done

        echo "Creating isolated test database: $UNIQUE_DB_NAME from base template: $BASE_TEMPLATE_DB"
        python -c "
        import os
        import psycopg
        from psycopg import sql
        
        unique_db = os.environ['UNIQUE_DB_NAME']
        base_template = os.environ['BASE_TEMPLATE_DB']
        conn_str = f'postgresql://integration_user:integration_password@localhost:5432/postgres'
        
        with psycopg.connect(conn_str, autocommit=True) as conn:
            with conn.cursor() as cur:
                # Check if database already exists and drop it to ensure clean state
                cur.execute(sql.SQL('SELECT 1 FROM pg_database WHERE datname = %s'), (unique_db,))
                if cur.fetchone():
                    print(f'Dropping existing database: {unique_db}')
                    cur.execute(sql.SQL('DROP DATABASE {}').format(sql.Identifier(unique_db)))
                
                # Create new isolated database from base template
                print(f'Creating database: {unique_db} from template: {base_template}')
                cur.execute(sql.SQL('CREATE DATABASE {} TEMPLATE {}').format(
                    sql.Identifier(unique_db),
                    sql.Identifier(base_template)
                ))
        "

        # Set the database name for subsequent steps
        echo "PG_DBNAME=$UNIQUE_DB_NAME" >> $GITHUB_ENV
        echo "DB_NAME=$UNIQUE_DB_NAME" >> $GITHUB_ENV
        echo "PG_QUEUE_DB=$UNIQUE_DB_NAME" >> $GITHUB_ENV

        if [[ "${{ matrix.requires_redis }}" == "true" ]]; then
          echo "Waiting for Redis..."
          for i in {1..30}; do
            if redis-cli -h localhost -p 6379 ping >/dev/null 2>&1; then
              echo "Redis ready"
              break
            fi
            sleep 2
          done
        fi

    - name: Verify extensions
      shell: micromamba-shell {0}
      run: |
        python -c "
        import os
        import psycopg
        db_name = os.environ['PG_DBNAME']
        conn_str = f'postgresql://integration_user:integration_password@localhost:5432/{db_name}'
        with psycopg.connect(conn_str, autocommit=True) as conn:
            with conn.cursor() as cur:
                cur.execute('SELECT extname FROM pg_extension WHERE extname = %s', ('pg_cron',))
                if not cur.fetchone():
                    raise Exception('pg_cron extension not found')
                cur.execute('SELECT extname FROM pg_extension WHERE extname = %s', ('roaringbitmap',))
                if not cur.fetchone():
                    print('roaringbitmap extension not found (optional)')
        "

    - name: Run tests
      shell: micromamba-shell {0}
      run: |
        PYTEST_FLAGS="--ci --pattern ${{ matrix.pattern }} --verbose"
        
        if [[ "${{ matrix.parallel }}" == "true" ]]; then
          PYTEST_FLAGS="$PYTEST_FLAGS --parallel"
        fi
        
        if [[ "${{ github.event_name }}" == "push" && "${{ github.ref }}" == "refs/heads/main" ]]; then
          PYTEST_FLAGS="$PYTEST_FLAGS --coverage"
        fi
        
        ./scripts/run_integration_tests.sh $PYTEST_FLAGS --no-setup

    - name: Upload artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ matrix.name }}
        path: |
          htmlcov/
          .coverage
          pytest-results.xml
          /tmp/ci_rocksdb*/
          /tmp/ci_rocksdict*/
        retention-days: 7

    - name: Upload coverage
      uses: codecov/codecov-action@v3
      if: github.event_name == 'push' && github.ref == 'refs/heads/main'
      with:
        file: ./coverage.xml
        flags: integration-${{ matrix.name }}

  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    needs: [build-postgres-image, integration-tests]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    services:
      postgres:
        image: ghcr.io/mpoppinga/postgres-test-extensions:${{ needs.build-postgres-image.outputs.image-tag }}
        env:
          POSTGRES_DB: partitioncache_integration
          POSTGRES_USER: integration_user
          POSTGRES_PASSWORD: integration_password
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U integration_user -d partitioncache_integration"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10
      
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10

    env:
      UNIQUE_DB_NAME: partitioncache_e2e_${{ github.run_id }}
      BASE_TEMPLATE_DB: partitioncache_integration
      CACHE_BACKEND: postgresql_array
      PG_HOST: localhost
      PG_PORT: 5432
      PG_USER: integration_user
      PG_PASSWORD: integration_password
      DB_HOST: localhost
      DB_PORT: 5432
      DB_USER: integration_user
      DB_PASSWORD: integration_password
      PG_QUEUE_HOST: localhost
      PG_QUEUE_PORT: 5432
      PG_QUEUE_USER: integration_user
      PG_QUEUE_PASSWORD: integration_password
      QUERY_QUEUE_PROVIDER: postgresql

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Setup micromamba
      uses: mamba-org/setup-micromamba@v1
      with:
        micromamba-version: 'latest'
        environment-file: .github/micromamba-env.yml
        init-shell: >-
          bash
        cache-environment: true
        post-cleanup: 'all'

    - name: Install PartitionCache
      shell: micromamba-shell {0}
      run: |
        pip install -e ".[testing,db]"
        pip install pytest-xdist  # Additional for parallel execution

    - name: Create and configure test database
      shell: micromamba-shell {0}
      run: |
        echo "Waiting for PostgreSQL..."
        for i in {1..30}; do
          if python -c "import psycopg; psycopg.connect('postgresql://integration_user:integration_password@localhost:5432/partitioncache_integration')" 2>/dev/null; then
            echo "PostgreSQL ready"
            break
          fi
          sleep 2
        done

        echo "Creating isolated test database: $UNIQUE_DB_NAME from base template: $BASE_TEMPLATE_DB"
        python -c "
        import os
        import psycopg
        from psycopg import sql
        
        unique_db = os.environ['UNIQUE_DB_NAME']
        base_template = os.environ['BASE_TEMPLATE_DB']
        conn_str = f'postgresql://integration_user:integration_password@localhost:5432/postgres'
        
        with psycopg.connect(conn_str, autocommit=True) as conn:
            with conn.cursor() as cur:
                # Check if database already exists and drop it to ensure clean state
                cur.execute(sql.SQL('SELECT 1 FROM pg_database WHERE datname = %s'), (unique_db,))
                if cur.fetchone():
                    print(f'Dropping existing database: {unique_db}')
                    cur.execute(sql.SQL('DROP DATABASE {}').format(sql.Identifier(unique_db)))
                
                # Create new isolated database from base template
                print(f'Creating database: {unique_db} from template: {base_template}')
                cur.execute(sql.SQL('CREATE DATABASE {} TEMPLATE {}').format(
                    sql.Identifier(unique_db),
                    sql.Identifier(base_template)
                ))
        "

        # Set the database name for subsequent steps
        echo "PG_DBNAME=$UNIQUE_DB_NAME" >> $GITHUB_ENV
        echo "DB_NAME=$UNIQUE_DB_NAME" >> $GITHUB_ENV
        echo "PG_QUEUE_DB=$UNIQUE_DB_NAME" >> $GITHUB_ENV

    - name: Run E2E tests
      shell: micromamba-shell {0}
      run: |
        ./scripts/run_integration_tests.sh \
          --ci \
          --no-setup \
          --pattern test_end_to_end_workflows \
          --verbose \
          --coverage

    - name: Upload E2E artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: e2e-test-results
        path: |
          htmlcov/
          .coverage
          pytest-results.xml
        retention-days: 7

  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: [build-postgres-image, integration-tests]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    services:
      postgres:
        image: ghcr.io/mpoppinga/postgres-test-extensions:${{ needs.build-postgres-image.outputs.image-tag }}
        env:
          POSTGRES_DB: partitioncache_integration
          POSTGRES_USER: integration_user
          POSTGRES_PASSWORD: integration_password
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U integration_user -d partitioncache_integration"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10

    env:
      UNIQUE_DB_NAME: partitioncache_perf_${{ github.run_id }}
      BASE_TEMPLATE_DB: partitioncache_integration
      CACHE_BACKEND: postgresql_array
      PG_HOST: localhost
      PG_PORT: 5432
      PG_USER: integration_user
      PG_PASSWORD: integration_password
      DB_HOST: localhost
      DB_PORT: 5432
      DB_USER: integration_user
      DB_PASSWORD: integration_password

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Setup micromamba
      uses: mamba-org/setup-micromamba@v1
      with:
        micromamba-version: 'latest'
        environment-file: .github/micromamba-env.yml
        init-shell: >-
          bash
        cache-environment: true
        post-cleanup: 'all'

    - name: Install PartitionCache
      shell: micromamba-shell {0}
      run: |
        pip install -e ".[testing,db]"
        pip install pytest-xdist  # Additional for parallel execution

    - name: Create and configure test database
      shell: micromamba-shell {0}
      run: |
        echo "Waiting for PostgreSQL..."
        for i in {1..30}; do
          if python -c "import psycopg; psycopg.connect('postgresql://integration_user:integration_password@localhost:5432/partitioncache_integration')" 2>/dev/null; then
            echo "PostgreSQL ready"
            break
          fi
          sleep 2
        done

        echo "Creating isolated test database: $UNIQUE_DB_NAME from base template: $BASE_TEMPLATE_DB"
        python -c "
        import os
        import psycopg
        from psycopg import sql
        
        unique_db = os.environ['UNIQUE_DB_NAME']
        base_template = os.environ['BASE_TEMPLATE_DB']
        conn_str = f'postgresql://integration_user:integration_password@localhost:5432/postgres'
        
        with psycopg.connect(conn_str, autocommit=True) as conn:
            with conn.cursor() as cur:
                # Check if database already exists and drop it to ensure clean state
                cur.execute(sql.SQL('SELECT 1 FROM pg_database WHERE datname = %s'), (unique_db,))
                if cur.fetchone():
                    print(f'Dropping existing database: {unique_db}')
                    cur.execute(sql.SQL('DROP DATABASE {}').format(sql.Identifier(unique_db)))
                
                # Create new isolated database from base template
                print(f'Creating database: {unique_db} from template: {base_template}')
                cur.execute(sql.SQL('CREATE DATABASE {} TEMPLATE {}').format(
                    sql.Identifier(unique_db),
                    sql.Identifier(base_template)
                ))
        "

        # Set the database name for subsequent steps
        echo "PG_DBNAME=$UNIQUE_DB_NAME" >> $GITHUB_ENV
        echo "DB_NAME=$UNIQUE_DB_NAME" >> $GITHUB_ENV

    - name: Run performance tests
      shell: micromamba-shell {0}
      run: |
        ./scripts/run_integration_tests.sh \
          --ci \
          --no-setup \
          --pattern performance \
          --verbose

    - name: Upload performance artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: performance-test-results
        path: |
          pytest-results.xml
          performance-results/
        retention-days: 30

  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [integration-tests, e2e-tests, performance-tests]
    if: always()
    
    steps:
    - name: Check results
      run: |
        echo "Integration Test Summary"
        echo "======================="
        
        if [[ "${{ needs.integration-tests.result }}" == "success" ]]; then
          echo "Integration tests: PASSED"
        else
          echo "Integration tests: FAILED"
          exit 1
        fi
        
        if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
          if [[ "${{ needs.e2e-tests.result }}" == "success" ]]; then
            echo "E2E tests: PASSED"
          else
            echo "E2E tests: FAILED"
            exit 1
          fi
          
          if [[ "${{ needs.performance-tests.result }}" == "success" ]]; then
            echo "Performance tests: PASSED"
          else
            echo "Performance tests: FAILED"
            exit 1
          fi
        fi
        
        echo "All tests completed successfully"